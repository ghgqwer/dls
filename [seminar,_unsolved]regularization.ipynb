{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUn4MDRPvXGr"
      },
      "source": [
        "<p style=\"align: center;\"><img align=center src=\"https://drive.google.com/uc?export=view&id=1aS4vX-ucDKBmZmZMrBwgjl_DvLAadX2C\" width=900/></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co-eo4BURtaT"
      },
      "source": [
        "<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n",
        "\n",
        "<h1 style=\"text-align: center;\"><b>Семинар. Регуляризация в линейных алгоритмах</b></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRoRKVq43yvE"
      },
      "source": [
        "В этом семинаре мы поговорим об $L_1$- и $L_2$-регуляризации линейной регрессии, а также об ElasticNet. Реализуем линейную регресиию с Lasso-регуляризацией и сравним реализацию с моделью из sklearn.\n",
        "\n",
        "Зачастую модель машинного обучения обучается на зашумлённых данных, то есть данных с ошибками и случайными отклонениями. Модель машинного обучения, которая обучается на минимизацию функции потерь, не может автоматически понять, где в датасете реальные важные закономерности, а где -- ошибки и случайные совпадения. Нам бы хотелось заставить модель **не переобучаться** под такие проблемы в данных и вычленять только неслучаные закономерности. Иначе, идеально обучившись на датасете с шумом, мы можем получить плохой результат на тестовых данных.\n",
        "\n",
        "На практике переобучение проявляется в излишней сложности модели. **Регуляризация** -- это метод борьбы с переобучением, который штрафует модель за излишнюю сложность сложность, что позволяет строить более простые (и потому стабильные) зависимости.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yBNj-arF6FO"
      },
      "source": [
        "Еще одной проблемой, специфичной для линейных моделей, является **мультиколлинеарность**. Как разбиралось на лекции, если оптимальных решений задачи минимизации оказывается бесконечно много, то коэффициенты модели могут принимать какие угодно огромные значения. **Вывод**: необходимо *ограничить величину* коэффициентов модели.\n",
        "\n",
        "Для линейной модели дополнительные ограничения на веса выполняют роль регуляризации.\n",
        "\n",
        "Функция потерь для линейной регрессии с регуляризацией выглядит следующим образом:\n",
        "$$L(\\mathbf{w}) = \\frac{1}{\\ell}\\sum_{i=1}^{\\ell}(\\langle \\mathbf{w} , x^i \\rangle - y^i)^2 + R(\\tilde{ \\mathbf{w}}) \\rightarrow \\min_{w}$$\n",
        "где\n",
        "* $x^i = (1, x^i_1, \\ldots, x^i_n)$ --- вектор признаков $i$-ого объекта;\n",
        "* $y^i \\in\\mathbb{R}$ --- правильный ответ на $i$-ом объекте;\n",
        "* $\\mathbf{w} = (w_0, w_1, \\ldots, w_n)$ --- вектор весов ($w_0$ --- свободный член).\n",
        "* $\\tilde {\\mathbf{w}} =  (w_1, \\ldots, w_n)$ --- вектор весов без свободного члена.\n",
        "\n",
        "Последнее слагаемое определяет вид регуляризации.\n",
        "* $L_1$-регуляризация (LASSO, least absolute shrinkage and selection operator), регуляризационное слагаемое равно $$R( \\mathbf{\\tilde w}) = \\lambda|| \\mathbf{\\tilde {w}}||_1 = \\lambda (|w_1| + \\ldots + |w_n|);$$\n",
        "* $L_2$-регуляризация (Ridge), регуляризационное слагаемое равно $$R(\\tilde{ \\mathbf{w}}) = \\lambda||\\tilde{ \\mathbf{w}}||_2^2 = \\lambda(|w_1|^2 + \\ldots + |w_n|^2);$$\n",
        "* ElasticNet -- комбинация двух предыдущих, регуляризационное слагаемое равно $$R(\\tilde{ \\mathbf{w}}) = \\alpha ||\\tilde{\\mathbf{w}}||_1+ \\beta ||\\tilde {\\mathbf{w}}||_2^2.$$\n",
        "\n",
        "Обратите внимание, что во всех случаях **коэффициент $w_0$ не участвует в сумме!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LjjtruRfRtaW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.linalg as sla\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i8WNBT5sePU"
      },
      "source": [
        "## Lasso-регрессия\n",
        "\n",
        "В LASSO-регрессии мы штрафуем модель **на сумму модулей всех ее весов**.\n",
        "\n",
        "**Лосс:** $$L(\\mathbf{w}) = \\frac{1}{\\ell} ||X\\mathbf{w} - \\mathbf{y}||^2_2 + \\lambda ||\\tilde{\\mathbf{w}}||_1,$$ где $\\lambda$ -- гиперпараметр, отвечающий за степень регуляризации.\n",
        "\n",
        "В привычном понимании:\n",
        "\n",
        "**Лосс:** $$L(\\mathbf{w}) = \\frac{1}{\\ell}\\sum_{i=1}^{\\ell}\\left(\\sum_{j=0}^{n} x_{ij}w_j - y_i\\right)^2 + \\lambda\\sum_{j=1}^{n}|w_j|$$\n",
        "\n",
        "\n",
        "\n",
        "**Градиент:**\n",
        "$$\n",
        "\\frac{\\partial{L}}{\\partial{\\mathbf{w}}}\n",
        "= \\frac{2}{\\ell}\\cdot X^T(X\\mathbf{w} - \\mathbf{y}) + \\lambda (0, \\mathrm{sign}(w_1), \\ldots, \\mathrm{sign}(w_n))^T.\n",
        "$$\n",
        "\n",
        "Будем считать, что $|\\cdot|$ -- дифференцируемая функция, ее производной является $sign(\\cdot)$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ETKNC1HxlgXd"
      },
      "outputs": [],
      "source": [
        "def soft_sign(x, eps=1e-7):\n",
        "    if abs(x) > eps:\n",
        "        return np.sign(x)\n",
        "    return x / eps\n",
        "\n",
        "np_soft_sign = np.vectorize(soft_sign)\n",
        "\n",
        "\n",
        "class MyLassoRegression(object):\n",
        "    def __init__(self, C=1):\n",
        "        self.coef_ = None\n",
        "        self.intercept_ = None\n",
        "        self.C = C\n",
        "\n",
        "    def regularization_term(self, weights):\n",
        "        signs =  np.np_soft_sign(weights) # YOUR CODE. Calculate soft signs of weights  # [n+1, 1]\n",
        "        signs[0] = 0  # Не нужно регуляризовывать по свободному члену\n",
        "        return signs\n",
        "\n",
        "    def grad(self, X, y, weights):\n",
        "        y_pred = (X @ weights)  # [l, 1]\n",
        "\n",
        "        basic_term =  (2. / (X.shape[0])) * X.T @ (y_pred - y) # YOUR CODE. Calulate basic term of loss  # [n+1, 1]\n",
        "\n",
        "        regularization_term = self.regularization_term(weights)  # [n+1, 1]\n",
        "\n",
        "        return basic_term + self.C * regularization_term  # [n+1, 1]\n",
        "\n",
        "\n",
        "    def fit(self, X, y, max_iter=100, lr=0.1):\n",
        "        # Принимает на вход X, y и вычисляет веса по данной выборке.\n",
        "        # Не забудьте про фиктивный признак, равный 1!\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "        assert len(y.shape) == 1 and len(X.shape) == 2\n",
        "        assert X.shape[0] == y.shape[0]\n",
        "\n",
        "        y = y[:, np.newaxis]\n",
        "\n",
        "        l, n = X.shape\n",
        "\n",
        "        # Добавляем признак из единиц\n",
        "        X_train = np.hstack([np.ones([l, 1]), X])  # [ell, n + 1]\n",
        "\n",
        "        # Инициализируем веса\n",
        "        weights = np.random.randn(n + 1, 1)\n",
        "\n",
        "        losses = []\n",
        "\n",
        "        for iter_num in range(max_iter):\n",
        "            # calculate grad\n",
        "            grad = self.grad(X_train, y, weights)\n",
        "            # update weights\n",
        "            weights -= grad * lr / ((iter_num + 1) ** 0.5)\n",
        "\n",
        "            # calculate loss\n",
        "            loss = np.mean((X_train @ weights - y) ** 2) + self.C * np.sum(np.abs(weights[1:]))\n",
        "            losses.append(loss)\n",
        "\n",
        "        # assign coef, intersept\n",
        "        self.coef_ = weights[1:]\n",
        "        self.intercept_ = weights[0]\n",
        "\n",
        "        return losses\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.array(X)\n",
        "        y_pred = X @ self.coef_ + self.intercept_\n",
        "\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Php_z5Yv2Iku"
      },
      "source": [
        "Протестируем нашу функцию на одномерной регрессии."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jqo5nBBp2Wzy"
      },
      "outputs": [],
      "source": [
        "def linear_expression(x):\n",
        "    return 5 * x + 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tnWKgFrL1zHF"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "objects_num = 50\n",
        "X = np.linspace(-5, 5, objects_num)\n",
        "y = linear_expression(X) + np.random.randn(objects_num) * 5\n",
        "\n",
        "# выделим половину объектов на тест\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8oUXohPi2SsZ"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(X, linear_expression(X), label='real', c='g')\n",
        "plt.scatter(X_train, y_train, label='train', c='b')\n",
        "plt.scatter(X_test, y_test, label='test', c='orange')\n",
        "\n",
        "plt.title(\"Generated dataset\")\n",
        "plt.grid(alpha=0.2)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BV7XBQ782ow-"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'np_soft_sign'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m regressor \u001b[38;5;241m=\u001b[39m MyLassoRegression()\n\u001b[0;32m----> 3\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mregressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m regressor\u001b[38;5;241m.\u001b[39mpredict(X_test[:, np\u001b[38;5;241m.\u001b[39mnewaxis])\n",
            "Cell \u001b[0;32mIn[2], line 52\u001b[0m, in \u001b[0;36mMyLassoRegression.fit\u001b[0;34m(self, X, y, max_iter, lr)\u001b[0m\n\u001b[1;32m     48\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iter_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# calculate grad\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# update weights\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     weights \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m grad \u001b[38;5;241m*\u001b[39m lr \u001b[38;5;241m/\u001b[39m ((iter_num \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n",
            "Cell \u001b[0;32mIn[2], line 25\u001b[0m, in \u001b[0;36mMyLassoRegression.grad\u001b[0;34m(self, X, y, weights)\u001b[0m\n\u001b[1;32m     21\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (X \u001b[38;5;241m@\u001b[39m weights)  \u001b[38;5;66;03m# [l, 1]\u001b[39;00m\n\u001b[1;32m     23\u001b[0m basic_term \u001b[38;5;241m=\u001b[39m  (\u001b[38;5;241m2.\u001b[39m \u001b[38;5;241m/\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])) \u001b[38;5;241m*\u001b[39m X\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m (y_pred \u001b[38;5;241m-\u001b[39m y) \u001b[38;5;66;03m# YOUR CODE. Calulate basic term of loss  # [n+1, 1]\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m regularization_term \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregularization_term\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [n+1, 1]\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m basic_term \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC \u001b[38;5;241m*\u001b[39m regularization_term\n",
            "Cell \u001b[0;32mIn[2], line 16\u001b[0m, in \u001b[0;36mMyLassoRegression.regularization_term\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregularization_term\u001b[39m(\u001b[38;5;28mself\u001b[39m, weights):\n\u001b[0;32m---> 16\u001b[0m     signs \u001b[38;5;241m=\u001b[39m  \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnp_soft_sign\u001b[49m(weights) \u001b[38;5;66;03m# YOUR CODE. Calculate soft signs of weights  # [n+1, 1]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     signs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Не нужно регуляризовывать по свободному члену\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m signs\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/__init__.py:414\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchar\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mchar\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m char\u001b[38;5;241m.\u001b[39mchararray\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'np_soft_sign'"
          ]
        }
      ],
      "source": [
        "regressor = MyLassoRegression()\n",
        "\n",
        "losses = regressor.fit(X_train[:, np.newaxis], y_train)\n",
        "\n",
        "predictions = regressor.predict(X_test[:, np.newaxis])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTYW_rKw4jun"
      },
      "outputs": [],
      "source": [
        "regressor.coef_, regressor.intercept_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCTi2zP54fEj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(losses, label='loss')\n",
        "plt.legend(fontsize=14)\n",
        "plt.xlabel('iter', fontsize=14)\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMKUq3GC2c-F"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(X, linear_expression(X), label='real', c='g')\n",
        "plt.plot(X, regressor.predict(X[:, np.newaxis]))\n",
        "\n",
        "plt.scatter(X_train, y_train, label='train', c='b')\n",
        "plt.scatter(X_test, y_test, label='test', c='orange')\n",
        "\n",
        "plt.title(\"Generated dataset\")\n",
        "plt.grid(alpha=0.2)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwgtaI8algCR"
      },
      "source": [
        "## Загрузка датасета\n",
        "Загрузим набор данных, с которым мы будем работать. В библиотеке scikit-learn есть множество тренировочных наборов данных для освоения и проверки методов машинного обучения. Мы будем работать с датасетом Diabetes. Этот датасет содержит данные о развитии диабета у пациента. Всего в датасете 10 признаков.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=19oN1ydcPobFRKc6Bx6Bf8tLVmI4Kh4g4\" width=\"400\">\n",
        "\n",
        "Стандартные наборы данных в scikit-learn находятся в модуле sklearn.datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIRwIhBWlgCU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_diabetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuxTXnfjlgCh"
      },
      "outputs": [],
      "source": [
        "data = load_diabetes()\n",
        "\n",
        "print(data['DESCR'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os_ObK2nlgCs"
      },
      "source": [
        "### Выделение данных\n",
        "\n",
        "Выделим матрицу объекты-признаки в переменную $X$, правильные ответы --- в переменную $y$. Используем библиотеку pandas. Для отображения информации о наборе данных используем функцию pd.describe, которая отображает полезные статистики из набора: средние значения признаков, минимум, максимум, медиану и др."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PZXmxzylgCv"
      },
      "outputs": [],
      "source": [
        "X = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
        "y = data['target']\n",
        "\n",
        "X.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrYEfpne3pRl"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBMX_Qx032ca"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled =  # YOUR CODE. Fit and apply scaler\n",
        "X_test_scaled =  # YOUR CODE. Apply scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRiuFACyTpau"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE. Verify that scaler worked OK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdQ8q3B54PDQ"
      },
      "outputs": [],
      "source": [
        "model = MyLassoRegression(C=0.001)\n",
        "losses = model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8InsmEhD6Y3e"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(losses, label='loss')\n",
        "plt.legend(fontsize=14)\n",
        "plt.xlabel('iter', fontsize=14)\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wefA3bz24GH6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 8))\n",
        "plt.bar(X.columns, model.coef_.ravel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2ZnL6Lr6SE5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "y_train_prediction = model.predict(X_train_scaled)\n",
        "y_test_prediction = model.predict(X_test_scaled)\n",
        "\n",
        "print(f'Train MSE: {mean_squared_error(y_train, y_train_prediction)}')\n",
        "print(f'Test MSE: {mean_squared_error(y_test, y_test_prediction)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDf-d8NK8Ge9"
      },
      "outputs": [],
      "source": [
        "model.coef_, model.intercept_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEiaIt-Y62mJ"
      },
      "source": [
        "## Величина весов в зависимости от коэффициента регуляризации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uGJXX5X6oTm"
      },
      "outputs": [],
      "source": [
        "reg_coefs = np.linspace(10, 100, 50)\n",
        "\n",
        "weights = np.empty((len(X.columns), 0))\n",
        "for C in reg_coefs:\n",
        "    lasso_regressor = MyLassoRegression(C=C)\n",
        "    lasso_regressor.fit(X_train_scaled, y_train, lr=0.05, max_iter=5000)\n",
        "    weights = np.hstack((weights, lasso_regressor.coef_.reshape(-1, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NByRDwXt3WjB"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "\n",
        "for weights_for_feature, column_name in zip(weights, X.columns):\n",
        "    plt.plot(reg_coefs, weights_for_feature, label=f'weights of feature {column_name}')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xYg6aFK_wZN"
      },
      "source": [
        "Построим такие же графики для реализации из sklearn:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjronqkT_vEM"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zi5jb6VG_qDD"
      },
      "outputs": [],
      "source": [
        "reg_coefs = np.linspace(5, 50, 50)\n",
        "\n",
        "weights = np.empty((len(X.columns), 0))\n",
        "for C in reg_coefs:\n",
        "    lasso_regressor = Lasso(alpha=C)\n",
        "    lasso_regressor.fit(X_train_scaled, y_train)\n",
        "    weights = np.hstack((weights, lasso_regressor.coef_.reshape(-1, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "8ElcqB1HUsWb",
        "outputId": "1c1fa0f7-95a3-4cba-9c88-b9e55a314a84"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c88e5fd527f9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mweights_for_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg_coefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_for_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'weights of feature {column_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "\n",
        "for weights_for_feature, column_name in zip(weights, X.columns):\n",
        "    plt.plot(reg_coefs, weights_for_feature, label=f'weights of feature {column_name}')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDY8EJmPsrCy"
      },
      "source": [
        "# 2.1. Ridge регрессия (L2-регуляризация)\n",
        "\n",
        "В ridge мы штрафуем модель также на сумму квадратов всех ее весов, таким образом:\n",
        "\n",
        "**Лосс:**\n",
        "$$L(\\mathbf{w}) = ||X\\mathbf{w} - \\mathbf{y}||^2_2 + \\lambda||\\mathbf{\\tilde{w}}||^2_2 = \\sum_{i=1}^{\\ell}\\left(\\sum_{j=0}^{n} x_{ij}w_j - y_i\\right)^2 + \\lambda\\sum_{j=1}^{n}w_j^2,$$\n",
        "где $\\lambda$ --- гиперпараметр, отвечающий за степень регуляризации.\n",
        "\n",
        "Что стоит сказать про значения признаков? Они должны быть стандартизованы для одинаковых штрафов относительно друг друга! (используется связка с `sklearn.preprocessing.StandardScaler`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0FPG3-bAYKh"
      },
      "source": [
        "Сравнение с графиками для Ridge-регрессии:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6SFVdYc_8f6"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "reg_coefs = np.linspace(1, 10000, 100)\n",
        "\n",
        "weights = np.empty((len(X.columns), 0))\n",
        "for C in reg_coefs:\n",
        "    ridge_regressor = Ridge(C)\n",
        "    ridge_regressor.fit(X_train_scaled, y_train)\n",
        "    weights = np.hstack((weights, ridge_regressor.coef_.reshape(-1, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wd7adQ0WU3qX"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "\n",
        "for weights_for_feature, column_name in zip(weights, X.columns):\n",
        "    plt.plot(reg_coefs, weights_for_feature, label=f'weights of feature {column_name}')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ker3ZqpRjhIA"
      },
      "source": [
        "Различия между $L_1$- и $L_2$-регуляризациями:\n",
        "\n",
        "- Lasso **сложнее обучать** из-за отсутствия аналитического решения\n",
        "- В Lasso появляется **зануление весов** для некоторых признаков"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-l3qGrmhlyi"
      },
      "source": [
        "## Для самостоятельного изучения: реализация Ridge-регрессии\n",
        "\n",
        "Аналогично предыдущим заданиям нужно рассчитать значение градиента $\\displaystyle\\frac{\\partial{L}}{\\partial{\\mathbf{w}}}$.\n",
        "\n",
        "**Градиент:**\n",
        "$$\n",
        "\\frac{\\partial{L}}{\\partial{\\mathbf{w}}}\n",
        "= \\frac{2}{\\ell}\\cdot X^T(X\\mathbf{w} - \\mathbf{y}) + 2\\lambda \\cdot (0, w_1, \\ldots, w_n)^T.\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R39nSHvmIRqp"
      },
      "outputs": [],
      "source": [
        "class MyRidgeRegression(object):\n",
        "    def __init__(self, C=1):\n",
        "        self.coef_ = None\n",
        "        self.intercept_ = None\n",
        "        self.C = C\n",
        "\n",
        "    def regularization_term(self, weights):\n",
        "        outp = 2 * weights.copy()\n",
        "        outp[0] = 0  # Не нужно регуляризовывать по свободному члену\n",
        "        return outp\n",
        "\n",
        "    def grad(self, X, y, weights):\n",
        "        y_pred = (X @ weights)  # [ell, 1]\n",
        "\n",
        "        basic_term = 2. / X.shape[0] * (X.T @ (y_pred - y))\n",
        "\n",
        "        regularization_term = self.regularization_term(weights)\n",
        "\n",
        "        return basic_term + self.C * regularization_term\n",
        "\n",
        "\n",
        "    def fit(self, X, y, max_iter=100, lr=0.1):\n",
        "        # Принимает на вход X, y и вычисляет веса по данной выборке.\n",
        "        # Не забудьте про фиктивный признак, равный 1!\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "        assert len(y.shape) == 1 and len(X.shape) == 2\n",
        "        assert X.shape[0] == y.shape[0]\n",
        "\n",
        "        y = y[:, np.newaxis]\n",
        "\n",
        "        l, n = X.shape\n",
        "\n",
        "        # Добавляем признак из единиц\n",
        "        X_train = np.hstack([np.ones([l, 1]), X])  # [l, n+1]\n",
        "\n",
        "        # Инициализируем веса\n",
        "        weights = np.random.randn(n+1, 1)\n",
        "\n",
        "        losses = []\n",
        "\n",
        "        for iter_num in range(max_iter):\n",
        "            # calculate grad\n",
        "            grad = self.grad(X_train, y, weights)\n",
        "            # update weights\n",
        "            weights -= grad * lr / ((iter_num + 1) ** 0.5)\n",
        "\n",
        "            # calculate loss\n",
        "            loss = np.mean((X_train @ weights - y) ** 2) + self.C * np.sum(np.abs(weights[1:]))\n",
        "            losses.append(loss)\n",
        "\n",
        "        # assign coef, intersept\n",
        "        self.coef_ = weights[1:]\n",
        "        self.intercept_ = weights[0]\n",
        "\n",
        "        return losses\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.array(X)\n",
        "        y_pred = X @ self.coef_ + self.intercept_\n",
        "\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Давайте подробно разберем строку кода:\n",
        "\n",
        "np_soft_sign = np.vectorize(soft_sign)\n",
        "Что такое np.vectorize?\n",
        "\n",
        "np.vectorize — это функция из библиотеки NumPy, которая позволяет упрощать операции над массивами, применяя указанную функцию к каждому элементу массива.\n",
        "\n",
        "Зачем это нужно?\n",
        "\n",
        "Когда мы пишем функцию, такую как soft_sign, она принимает одно значение (например, число, float или int) и возвращает знак этого числа либо возвращает значение, нормализованное по маленькому значению eps. Например, для одного элемента это может выглядеть так:\n",
        "\n",
        "result = soft_sign(0.01)  # Вернет 1.0, если 0.01 > 1e-7\n",
        "Однако если вам нужно применить эту функцию к массиву (например, к массиву весов), вам нужно либо написать цикл, чтобы снова и снова вызывать soft_sign для каждого элемента, либо использовать векторизованную версию.\n",
        "\n",
        "Как работает np.vectorize?\n",
        "\n",
        "Когда мы используем np.vectorize, он создает новую функцию, которая может принимать вектор (или массив) в качестве входных данных, и автоматически применяет исходную функцию soft_sign ко всем элементам массива.\n",
        "\n",
        "Пример использования np.vectorize:\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def example_function(x):\n",
        "    return x ** 2\n",
        "\n",
        "# Создаем векторизованную версию функции\n",
        "vectorized_function = np.vectorize(example_function)\n",
        "\n",
        "# Применяем векторизованную функцию к массиву\n",
        "array = np.array([1, 2, 3, 4])\n",
        "result = vectorized_function(array)\n",
        "\n",
        "# result будет [1, 4, 9, 16]\n",
        "print(result)\n",
        "Применение к вашему коду\n",
        "\n",
        "В вашем случае np_soft_sign — это векторизованная версия функции soft_sign, которая позволяет применять ее к массивам весов:\n",
        "\n",
        "signs = np_soft_sign(weights)  # weights - это массив (например, [w_0, w_1, ..., w_n])\n",
        "После этого signs будет массивом, где каждая ячейка содержит \"мягкий знак\" соответствующего элемента из weights. Например, если weights = [0.01, -0.001, 0.15], то после применения np_soft_sign к этому массиву мы получим массив с знаками или нормализованными значениями в зависимости от условий в функции soft_sign.\n",
        "\n",
        "Заключение\n",
        "\n",
        "Использование np.vectorize упрощает ваши операции с массивами и позволяет вам писать более чистый и лаконичный код, избегая необходимости явно использовать циклы для обработки данных. Это особенно полезно в контексте машинного обучения и работы с большими наборами данных, так как производительность вашего кода может значительно повыситься за счет того, что NumPy оптимизирован для работы с массивами."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Давайте подробно разберем функцию soft_sign и объясним, почему в ней используется проверка на значение:\n",
        "\n",
        "def soft_sign(x, eps=1e-7):\n",
        "    if abs(x) > eps:\n",
        "        return np.sign(x)\n",
        "    return x / eps\n",
        "Основная цель функции soft_sign\n",
        "\n",
        "Функция soft_sign предназначена для определения \"мягкого знака\" (soft sign) числа. В контексте регуляризации L1 в Lasso-регрессии важно, чтобы функция не только возвращала знак числа (т.е. -1, 0 или 1), но также обрабатывала значения, близкие к нулю, чтобы предотвратить проблемы в процессе оптимизации.\n",
        "\n",
        "Разбор каждого элемента функции\n",
        "\n",
        "abs(x) > eps:\n",
        "\n",
        "Это условие проверяет, является ли абсолютное значение числа x достаточно большим (больше чем eps, где eps обычно равно (1 \\times 10^{-7})).\n",
        "Если x является довольно малым (например, 0.0001), то оно не будет рассматриваться как \"значимое\" значение. Это важно, так как вес, близкий к нулю, не должен вносить значительный вклад в регуляризацию, чтобы не влиять на обучение модели.\n",
        "np.sign(x):\n",
        "\n",
        "Если абсолютное значение x больше eps, то функция возвращает обычный знак числа с помощью np.sign, который:\n",
        "Возвращает 1, если x больше 0.\n",
        "Возвращает -1, если x меньше 0.\n",
        "Возвращает 0, если x равно 0.\n",
        "Это будет основной логикой, которая позволит нам получить \"значимый\" знак.\n",
        "return x / eps:\n",
        "\n",
        "Если x близок к 0 (меньше eps по абсолютному значению), функция возвращает x, деленное на eps.\n",
        "Это деление помогает предотвратить проблемы при вычислениях и обеспечивает более стабильную работу алгоритма. Например, при использовании этого значения для обновления весов, малые значения (которые могли бы быть просто сведены к нулю) всё же будут делиться на очень малое значение, что предотвратит деление на ноль в других частях алгоритма.\n",
        "Зачем это нужно?\n",
        "\n",
        "Стабильность вычислений:\n",
        "\n",
        "Когда значения весов становятся очень маленькими (но не нулевыми), они могут вызывать проблемы при обучении модели, включая числовые ошибки или \"подсчет\" их как нулевые значения. Учитывание небольших величин с помощью eps позволяет избежать этих проблем.\n",
        "Регуляризация:\n",
        "\n",
        "В контексте Lasso-регрессии цель состоит в том, чтобы некоторые веса могли быть занулены (отклонены), но при этом имелась возможность остановиться, если они ближе к нулю. Это \"мягкое\" округление позволяет некоторым весам быть маленькими, но не равными нулю, тем самым оставляя возможность для адаптации и улучшения модели в будущем.\n",
        "Пример работы функции soft_sign\n",
        "\n",
        "Для лучшего понимания, давайте проведем несколько примеров применения функции:\n",
        "\n",
        "# Примеры значений\n",
        "print(soft_sign(0.1))     # Выведет 1.0 (так как 0.1 > 1e-7)\n",
        "print(soft_sign(-0.5))    # Выведет -1.0 (так как -0.5 > 1e-7)\n",
        "print(soft_sign(0.0000001)) # Выведет 1.0 / 1e-7 = 1000000.0 (так как 0.0000001 < 1e-7)\n",
        "print(soft_sign(0))       # Выведет 0.0 (так как 0 < 1e-7)\n",
        "Как видно из этих примеров, функция soft_sign обрабатывает значения по-разному в зависимости от их абсолютного значения. Это обеспечивает контроль над тем, как модель будет реагировать на очень малые значения, что является важным аспектом при реализации Lasso-регрессии."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "С - значение силы регулизации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]]),\n",
              " array([[1., 1., 2.],\n",
              "        [1., 3., 4.],\n",
              "        [1., 5., 6.]]))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "X = np.array([[1, 2],\n",
        "              [3, 4],\n",
        "              [5, 6]])\n",
        "l, n = X.shape\n",
        "X_train = np.hstack([np.ones([l, 1]), X]) \n",
        "X, X_train"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
